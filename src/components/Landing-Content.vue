<template>
  <div>
    <h1 class="header-big">AI Observatory</h1>

    <p>
      &lsquo;Artificial Intelligence&rsquo;, &lsquo;Machine Learning&rsquo;,
      &lsquo;Big Data&rsquo; and &lsquo;Automation&rsquo; are routinely used to
      invoke utopian vistas of objective, efficient and incorruptible systems
      with the potential to revolutionise society. We are told, repeatedly, that
      with enough data and computational power, applying the unbiased logic of
      machines and computer software, long-standing social problems &ndash; from
      crime to poverty &ndash; can be alleviated.&nbsp;
    </p>

    <blockquote cite="http://">
      The language of &lsquo;AI&rsquo; and the &lsquo;digital revolution&rsquo;,
      however, hides the crossed wires, the missing parts and the poisonous
      exhaust underneath the gleaming hoods of computers and data
      machines.&nbsp;
    </blockquote>

    <p>
      The potential of data, computers and networked technologies for social and
      scientific progress is undoubtable &ndash; they can possess the capacity
      for processing information and performing cognitive tasks which far
      surpass human ability.&nbsp;
    </p>

    <p>
      The language of &lsquo;AI&rsquo; and the &lsquo;digital revolution&rsquo;,
      however, hides the crossed wires, the missing parts and the poisonous
      exhaust underneath the gleaming hoods of computers and data
      machines.&nbsp;
    </p>

    <div>
      <b-img
        center
        style="width: 100%"
        src="../../public/animation.gif"
        fluid
        alt="ml and big data walk into a bar"
      ></b-img>
    </div>

    <div class="modal-button-container">
      <b-button squared class="modal-button" v-b-modal="'illustration-legend'"
        >Map_Territories and Learning_Knowing
      </b-button>
      <b-modal id="illustration-legend" size="xl" hide-footer>
        <div class="d-block text-left">
          <p>Maps_Territories and Learning_Knowing:</p>
          <p>
            <br /><br />The illustrations in this narrative are an attempt to
            create a visual language for phenomenon around automated
            decision-making systems, and the various actors engaged in the
            structuring, running, subversion and through it, the ones exploited
            through it.
          </p>
          <p>
            The actors are an extension of an ongoing mapping that started out
            with the
            <a href="https://cis-india.github.io/cybersecurityvisuals/index"
              >Revisualising Cybersecurity project</a
            >, which shows the origin stories of <em>dineshan</em>. A
            manifestation of the intermingling of corporate and state interests
            around platforms and citizen/ user participation. This participation
            being rich sources of data extraction, referred to in many ways,
            most recently as "Surveillance Capitalism". These relationships are
            further explored in the comic "<a
              href="https://www.epw.in/engage/article/designing-democracy-does-personal-data-protection"
              >dad and his invisibility mundu</a
            >" to illustrate what could happen when there is a rift between
            legality and justice when it comes to legislation around data and
            privacy.
          </p>
          <p>
            This mapping or extension develops different relationships between
            dineshan(s) and the people they want to know, keeping in mind the
            unfolding nature of automated decision-making systems and machine
            learning models used around the world, but specifically in India.<br /><br />The
            CCTV&rsquo;d ones leaning heavily towards private and/or corporate
            interests represented without the crown, the ones with crowns are
            state bodies, often constituted by an electoral process directly or
            indirectly. <br /><br />The colour
            <span style="color: red"> red</span> is used often to indicate
            something that manifests in a tangible form: subject/citizens of a
            state, infrastructure that allows for participation/ interaction.
          </p>
          <p>
            The colour blue is usually an indicator of aggregated data and
            datasets that have been compressed or processed through manual
            moderation, paperwork and supervised/ unsupervised learning models.
          </p>
          <p>
            A mix of <span style="color: red"> red</span>,
            <span style="color: blue; background-color: white"> blue</span> and
            <span style="color: yellow"> yellow</span> indicates an extraction
            of behaviour that has been quantified in one or more ways, often
            under the label of "raw data''. Though while drawing these,
            <em>rawness</em> points more towards a metaphor for vegetables
            and<em> uncooked-ness</em> as opposed to referring to data as oil,
            from crude to pure.
          </p>
          <p>
            Green is usually an indicator of learnt (choice-probability based)
            abstraction that is part of a learning model that recognises human
            behaviours, through translation and matching depending on the task
            that is being automated. Typologies for images for facial
            recognition, or numbers and text for welfare, license plate id'ng.
          </p>
          <p>
            There is only one black box in the scheme of the illustration, it
            refers only to the environment in which either program are written
            or where they're parsed.
          </p>
          <p>
            In a mythical landscape of <em>dineshans</em> it is easier to assume
            transparency to non-anthropomorphised ADMS instead of allowing the
            persistence of dystopian blackboxes (usually a flowchart mnemonic)
            which pushes human agency from hope into despair. Which cannot be
            the consequence of mapping complex things. Dineshan is the only
            CCTV&rsquo;d anthropomorph, as they are a result of human agency
            directed one way or subverted in another.
          </p>
          <p>
            <br />The map underscores the importance of the territory, as does a
            learning model the importance of knowing contextually the lived
            experiences of people, that can only be categorised and generalised
            to a limit, linked data is not <em>the</em> map of a person&rsquo;s
            unique identity.
          </p>
        </div>
      </b-modal>
    </div>

    <p>
      This project is an attempt to critique the dominant narrative of
      &lsquo;Artificial Intelligence&rsquo; and &lsquo;data-driven
      governance&rsquo; in India, by <strong>documenting </strong>the use of
      Automated Decision Making Systems or ADMS, exploring their
      <strong>social</strong
      ><strong>, political and technological contexts</strong>, and documenting
      the actual and potential <strong>harms </strong>that they pose to
      individual and collective rights. It also provides activists, journalists,
      lawyers and affected individuals with the <strong>tools</strong> to
      understand and mitigate these harms using participatory legal processes
      and principles for design and regulation.&nbsp;
    </p>
    <div class="modal-button-container">
      <b-button squared class="modal-button" v-b-modal="'note-method'"
        >Brief Note on Method
      </b-button>
      <b-modal id="note-method" size="xl" hide-footer>
        <div class="d-block text-left">
          <h3>Brief Note on Method</h3>
          <p>
            <strong>Definitions</strong>: For the purpose of this toolkit, we
            shed the obfuscatory language of &lsquo;AI&rsquo; and artificial
            intelligence, which centres technology and data science, and use the
            term &lsquo;Automated Decision Making Systems&rsquo; or ADMS. ADMS
            is defined as &ldquo;any system which utilises computational and
            algorithmic tools to automatically process information and generate
            an output or decision which is of consequence to an individual or a
            community.&rdquo;&nbsp;
          </p>
          <p>
            A broad definition of ADMS has been used in order to invoke and
            re-center these systems as social and technical assemblages which
            operate within particular institutional and political contexts, and
            are used to make decisions which have consequences for individuals
            and communities &ndash; such as decisions about who to police, how
            to identify trustworthy citizens or when to provide credit and
            employment. ADMS and AI, are, however, closely related &ndash; the
            laws, policies, actors and institutions forming around
            &lsquo;AI&rsquo; are increasingly encouraging the automation and
            delegation of decision-making functions away from humans, as well as
            from democratic and participatory systems of decisions.
          </p>
          <p>
            <strong>Scope: </strong>While this toolkit covers some areas of
            private and consumer applications of ADMS, its primary focus is on
            the use of ADMS within public agencies and within contexts which
            have directly consequential impacts on individuals and communities,
            such as policing, government welfare, urban planning, and credit and
            finance. This focus is also in recognition of the impact that ADMS
            has on individuals and communities, often without their knowledge or
            ability to choose to participate in these systems &ndash; and as
            these technologies increasingly creep outside our online lives and
            into our material lives in ways which are often not recognised.
          </p>
        </div>
      </b-modal>
    </div>

    <h2>This toolkit is divided in the following parts:</h2>

    <ul>
      <li>
        <p><strong>A navigable database of ADMS in India&nbsp;</strong></p>
      </li>

      <li>
        <p>
          <strong
            >The Legal, Institutional and Technical Architecture of ADMS in
            India</strong
          >
          <a href="/Section1.pdf" download>(pdf)</a>
        </p>
        <ul>
          <li><p>Laws, Policies, Institutions and Actors</p></li>
          <li><p>Databases&nbsp;</p></li>
          <li><p>Algorithms</p></li>
        </ul>
      </li>

      <li>
        <p>
          <strong>Unpacking Algorithmic Harms</strong>
          <a href="/Section2.pdf" download>(pdf)</a>
        </p>
        <ul>
          <li><p>ADMS + Transparency and Accountability</p></li>
          <li><p>ADMS + Surveillance and Profiling</p></li>
          <li><p>ADMS + Dispossession</p></li>
          <li><p>ADMS + Discrimination</p></li>
        </ul>
      </li>

      <li>
        <p><strong>Tools and Agendas for Rights Against the Machine</strong></p>
        <ul>
          <li>
            <p>
              Applying Constitutional Principles to ADMS Design and Regulation
            </p>
          </li>
          <li>
            <p>Take Action! Participatory Tools for ADMS Accountability</p>
          </li>
        </ul>
      </li>
    </ul>
  </div>
</template>

<script></script>

<style lang="scss" scoped></style>
