<template>
  <div>
    <div>
      <b-img
        center
        style="width:80%; height: 660px; object-fit:cover"
        src="../../public/pimg1.png"
        fluid
        alt="ml and big data walk into a bar"
      ></b-img>
    </div>
    <h1>Introduction</h1>
    <p>
      &lsquo;Artificial Intelligence&rsquo;, &lsquo;Machine Learning&rsquo;,
      &lsquo;Big Data&rsquo; and &lsquo;Automation&rsquo; are routinely used to
      invoke utopian vistas of objective, efficient and incorruptible systems
      with the potential to revolutionise society. We are told, repeatedly, that
      with enough data and computational power, applying the unbiased logic of
      machines and computer software, long-standing social problems &ndash; from
      crime to poverty &ndash; can be alleviated.&nbsp;
    </p>
    <p>
      The potential of data, computers and networked technologies for social and
      scientific progress is undoubtable &ndash; they can possess the capacity
      for processing information and performing cognitive tasks which far
      surpass human ability.&nbsp;
    </p>
    <p>
      The language of &lsquo;AI&rsquo; and the &lsquo;digital revolution&rsquo;,
      however, hides the crossed wires, the missing parts and the poisonous
      exhaust underneath the gleaming hoods of computers and data
      machines.&nbsp;
    </p>
    <p>
      This project is an attempt to critique the dominant narrative of
      &lsquo;Artificial Intelligence&rsquo; and &lsquo;data-driven
      governance&rsquo; in India, by <strong>documenting </strong>the use of
      Automated Decision Making Systems or ADMS, exploring their
      <strong>social</strong
      ><strong>, political and technological contexts</strong>, and documenting
      the actual and potential <strong>harms </strong>that they pose to
      individual and collective rights. It also provides activists, journalists,
      lawyers and affected individuals with the <strong>tools</strong> to
      understand and mitigate these harms using participatory legal processes
      and principles for design and regulation.&nbsp;
    </p>
    <div>
      <b-button squared class="modal-button" v-b-modal="'note-method'"
        >Brief Note on Method
      </b-button>
      <b-modal id="note-method" size="xl" hide-footer>
        <div class="d-block text-left">
          <h3>Brief Note on Method</h3>
          <p>
            <strong>Definitions</strong>: For the purpose of this toolkit, we
            shed the obfuscatory language of &lsquo;AI&rsquo; and artificial
            intelligence, which centres technology and data science, and use the
            term &lsquo;Automated Decision Making Systems&rsquo; or ADMS. ADMS
            is defined as &ldquo;any system which utilises computational and
            algorithmic tools to automatically process information and generate
            an output or decision which is of consequence to an individual or a
            community.&rdquo;&nbsp;
          </p>
          <p>
            A broad definition of ADMS has been used in order to invoke and
            re-center these systems as social and technical assemblages which
            operate within particular institutional and political contexts, and
            are used to make decisions which have consequences for individuals
            and communities &ndash; such as decisions about who to police, how
            to identify trustworthy citizens or when to provide credit and
            employment. ADMS and AI, are, however, closely related &ndash; the
            laws, policies, actors and institutions forming around
            &lsquo;AI&rsquo; are increasingly encouraging the automation and
            delegation of decision-making functions away from humans, as well as
            from democratic and participatory systems of decisions.
          </p>
          <p>
            <strong>Scope: </strong>While this toolkit covers some areas of
            private and consumer applications of ADMS, its primary focus is on
            the use of ADMS within public agencies and within contexts which
            have directly consequential impacts on individuals and communities,
            such as policing, government welfare, urban planning, and credit and
            finance. This focus is also in recognition of the impact that ADMS
            has on individuals and communities, often without their knowledge or
            ability to choose to participate in these systems &ndash; and as
            these technologies increasingly creep outside our online lives and
            into our material lives in ways which are often not recognised.
          </p>
        </div>
      </b-modal>
    </div>

    <h2>This toolkit is divided in the following parts:</h2>

    <ul>
      <li>
        <p><strong>A navigable database of ADMS in India&nbsp;</strong></p>
      </li>

      <li>
        <p>
          <strong
            >The Legal, Institutional and Technical Infrastructures of ADMS in
            India</strong
          >
        </p>
        <ul>
          <li><p>Laws, Policies, Institutions and Actors</p></li>
          <li><p>Databases&nbsp;</p></li>
          <li><p>Algorithms</p></li>
        </ul>
      </li>

      <li>
        <p><strong>Unpacking Algorithmic Harms</strong> <a href="../../public/Section2.pdf">(pdf)</a> </p>
        <ul>
          <li><p>ADMS + Transparency and Accountability</p></li>
          <li><p>ADMS + Surveillance and Profiling</p></li>
          <li><p>ADMS + Dispossession</p></li>
          <li><p>ADMS + Discrimination</p></li>
        </ul>
      </li>

      <li>
        <p><strong>Tools and Agendas for Rights Against the Machine</strong></p>
        <ul>
          <li>
            <p>
              Applying Constitutional Principles to ADMS Design and Regulation
            </p>
          </li>
          <li>
            <p>Take Action! Participatory Tools for ADMS Accountability</p>
          </li>
        </ul>
      </li>
    </ul>

  </div>
</template>

<script></script>

<style lang="scss" scoped></style>
