<template>
  <b-tab title="Laws, Policies, Actors and Institutions" active>
    <p>
      To understand the consequences of the use of ADMS and AI, it is imperative
      to explore the political, legal and institutional context within which its
      development and deployment is taking place. This section marks out the
      legal and institutional frameworks within which AI and ADMS are being
      adopted in India, and the policies and actors which are shaping the manner
      in which it is developed and deployed.
    </p>
    <p><strong>The Politics of AI Policy in India</strong></p>
    <p>
      The use of &lsquo;AI&rsquo;-based computer systems in supporting
      government administration and decision-making in India can be traced back
      to at-least the 1980&rsquo;s, with the establishment of research centres
      for AI, like the Centre for the Development of Advanced Computing, or
      &lsquo;nodal centres&rsquo; within the Department of Electronics which
      developing AI systems for government administration, supported by
      international development organisations like the UNDP.
    </p>
    <p>
      Early examples of ADMS in India include systems like Eklavya, a software
      system which aided frontline child health workers with making decisions
      about diagnosis, health risk and future action for healthcare.<sup
        ><a href="#sdfootnote1sym" name="sdfootnote1anc"><sup>1</sup></a></sup
      >
      Similarly, there is documented use of &lsquo;Automated Legal Reasoning
      Systems&rsquo; under the Knowledge Based Computer Systems programme of the
      Government of India.<sup
        ><a href="#sdfootnote2sym" name="sdfootnote2anc"><sup>2</sup></a></sup
      >
      These systems implemented rule-based and logic-based programmes for
      decision-making, which were piloted in the fields of income tax, pension
      and customs. These systems attempted to encode the logic of statutory
      rules in these fields into programmatic computer languages in order to aid
      bureaucrats in complex legal and administrative problems. These early
      examples are indicative of the Government of India&rsquo;s desire to embed
      ADMS within government administration to ensure consistency in
      decision-making, and to assist administrative agencies in navigating and
      administering complex rule-based systems.
    </p>
    <p>
      The contemporary use of ADMS in India is also justified based on their
      efficiency in solving complex problems in government administration.
      However, today, ADMS adoption is occurring in a very different
      technological and political context, and this transformation is critical
      in understanding the role that ADMS plays in public agencies in India
      today.
    </p>
    <p>
      Developing &lsquo;AI&rsquo; and promoting computational data analytics
      within the government and the private sector alike has recently become a
      policy priority for the Government of India, as well as various state
      governments, over the last few years. Various &lsquo;AI&rsquo; policies
      have been released by the Government of India &ndash; from the government
      policy agency NITI Aayog&rsquo;s
      <a href="https://niti.gov.in/national-strategy-artificial-intelligence"
        >National Strategy for AI,</a
      >
      to
      <a
        href="https://www.meity.gov.in/artificial-intelligence-committees-reports"
        >reports of expert committees</a
      >
      constituted by the Ministry of Electronics and IT &ndash; which see AI as
      a transformational technology, and as a crucial &lsquo;factor of
      production&rsquo; for obtaining higher economic growth in the information
      economy. These policy documents have called for greater development and
      adoption of &lsquo;AI&rsquo; across the private and public sectors,
      ranging from healthcare to agriculture. According to some policy
      documents, &lsquo;AI&rsquo; is expected to operate as the infrastructure
      through which a number of applications and information-based tools can be
      built and used. For example, the Department of Telecommunications has
      <a
        href="https://www.tec.gov.in/pdf/Whatsnew/ARTIFICIAL%20INTELLIGENCE%20-%20INDIAN%20STACK.pd"
        >articulated</a
      >
      a vision for an &lsquo;AI Stack&rsquo; &ndash; a technological
      architecture for AI as infrastructure to be developed and used across a
      number of applications and domains.
    </p>
    <p>
      AI development has also been a policy agenda for state and local
      governments. Telangana, for example, has reflected its proposals to
      promote and utilise ADMS and AI systems across different industries and
      uses, in the &lsquo;<a
        href="https://it.telangana.gov.in/2020-is-telanganas-year-of-ai/"
        >2020 Year of AI Vision</a
      >&rsquo;. Other documents like &lsquo;<a
        href="https://indiaai.gov.in/research-reports/tamil-nadu-safe-ethical-artificial-intelligence-policy-2020"
        >Tamil Nadu Safe and </a
      ><a
        href="https://indiaai.gov.in/research-reports/tamil-nadu-safe-ethical-artificial-intelligence-policy-2020"
        >Ethical AI Policy</a
      >&rsquo; also indicate a growing recognition of the need to contend with
      emerging ethical issues arising from the use of AI, including fairness,
      transparency and accountability.
    </p>
    <p>
      The vision of &lsquo;AI&rsquo; articulated in these documents is one of a
      &lsquo;public good&rsquo;, championed by private firms and companies
      developing these technologies, and incentivised and legitimised through
      government policy, investment,and &lsquo;public-private
      partnerships&rsquo;. This vision of AI has also influenced key regulatory
      and policy developments in India, particularly regarding the governance of
      digital data. Government policy documents, such as
      <a
        href="https://economictimes.indiatimes.com/news/economy/indicators/budget-2019-in-economic-survey-a-terse-message-for-google-facebook/articleshow/70070224.cms?from=mdr"
        >Economic Survey of India of 2018-2019</a
      >, the
      <a
        href="https://m.economictimes.com/news/economy/policy/draft-ecomm-policy-seeks-to-set-up-regulator-restrict-data-storage/articleshow/76760134.cms"
        >Draft E-Commerce Policy</a
      >
      and the
      <a
        href="https://www.mygov.in/task/share-your-inputs-draft-non-personal-data-governance-framework/"
        >Report of the Committee of Experts on Non-Personal Data</a
      >, have attempted to reclassify &lsquo;data&rsquo; within digital
      environments as an economic asset, whose value can be
      &lsquo;unlocked&rsquo; or exploited through appropriately channeling them
      within AI or data analytics systems.
    </p>

    <blockquote cite="http://">
      The vision of &lsquo;AI&rsquo; articulated in these documents is one of a
      &lsquo;public good&rsquo;, championed by private firms and companies
      developing these technologies, and incentivised and legitimised through
      government policy, investment,and &lsquo;public-private
      partnerships&rsquo;.
    </blockquote>

    <p>
      The policy focus on spurring innovation through the deployment of
      government regulation has had a direct influence on legislative policy as
      well. The Personal Data Protection Bill, in 2019, had carved out
      <a
        href="https://economictimes.indiatimes.com/tech/internet/draft-data-protection-bill-allows-processing-sans-consent-for-security-credit-scores-debt-recovery/articleshow/72460269.cms?from=mdr"
        >specific exemptions</a
      >
      for activities like Credit Scoring and Fraud Detection, which are common
      use cases for ADMS. Similarly, the PDP Bill also
      <a
        href="https://indianexpress.com/article/opinion/columns/data-and-its-discontents-lok-sabha-personal-data-protection-bill-6197029/"
        >allowed</a
      >
      for the acquisition of any &lsquo;non-personal&rsquo; data by the
      Government, for &lsquo;better targeting&rsquo; of services or for the
      formulation of &lsquo;evidence-based policy&rsquo; &ndash; once again
      evidencing attempts to use &lsquo;big data analytics&rsquo; within ADMS to
      make consequential policy and administrative decisions.
    </p>
    <p>
      While there has been an increasing recognition of the risks posed by
      delegating decision-making to automated systems and &lsquo;AI&rsquo;,
      particularly on risks to data protection and privacy, policy documents
      have understood these are primarilyrisks caused by technological failure,
      which can be allayed by appropriate technical standards (such as
      anonymisation of data, or through &lsquo;consent management
      systems&rsquo;).
    </p>
    <p>
      However, even as &lsquo;AI&rsquo; policy which emerges from India
      recognises some risks and harms in the development and deployment of
      AI,<sup
        ><a href="#sdfootnote3sym" name="sdfootnote3anc"><sup>3</sup></a></sup
      >
      there is a disturbing lack of recognition or regulation around the systems
      currently in use and being deployed. As documented in this toolkit, many
      decisions consequential to individuals and communities are being delegated
      to algorithmic systems, varying in sophistication, but posing concerns
      &ndash; of democratic control, justice and self-determination &ndash;
      which are not reflected within policies which encourage the development
      and deployment of &lsquo;AI&rsquo; systems. In fact, even the documented
      deployment of current AI and Machine Learning systems does not reflect the
      concerns of data protection or &lsquo;ethical design&rsquo; which are
      envisaged in policy documents at the ministerial level, pointing to the
      complete absence of a structural framework to ensure accountability of
      ADMS on the ground, even as their harms are being recognised in policy.
      Instead, the development of these systems is taking place in a regulatory
      vacuum, resulting in a situation where important considerations of
      transparency, accountability and democratic control are not given their
      due regard.<sup
        ><a href="#sdfootnote4sym" name="sdfootnote4anc"><sup>4</sup></a></sup
      >
    </p>
    <p>
      Taking the gaze away from high-level policy documents on AI released by
      government agencies, the development of ADMS in India is being shaped, in
      fact, by a network of public and private actors, norms and institutions,
      seemingly unguided by the visions of &lsquo;ethics&rsquo; or &lsquo;social
      good&rsquo; articulated in policy documents. The case studies below shine
      a light on actors and institutions responsible for developing and
      deploying ADMS in India.
    </p>

    <div class="modal-button-container">
      <b-button class="modal-button" v-b-modal="'case-study-9'"
        >[Case Study: ADMS in Policing]</b-button
      >
      <b-modal id="case-study-9" size="xl" hide-footer>
        <div></div>
        <div class="d-block text-left">
          <h3>Case Study: ADMS in Policing</h3>
          <p>
            Since 2016, the Federation of the Indian Chambers of Commerce and
            Industry (FICCI), a major industry association in India, has been
            instituting the &lsquo;<a
              href="http://ficci.in/spdocument/23116/FICCI-Compendium-of-Best-Practices-in-sMART-Policing-2019.pdf"
              >Smart Policing Awards</a
            >&rsquo;, ostensibly with the intention of promoting practices for
            the safety and security of Indians. The awardees over the last four
            years have included Automated Decision Making Systems like the
            Punjab Artificial Intelligence System (PAIS),Trinetra in Uttar
            Pradesh, and Automated Facial Recognition and Number-Plate
            Recognition Systems in Madhya Pradesh, among others.
          </p>
          <p>
            Looking over the awardees of &lsquo;Smart Policing&rsquo; gives a
            good indication of the directions in which technology use in
            policing is heading, and the actors driving this change. Since the
            Crime and Criminal Tracking Network System (CCTNS) was first
            projected as the digital infrastructure to enable
            &lsquo;smarter&rsquo; policing in India, there has been a
            proliferation of data-driven and digital surveillance-based
            technologies among policing agencies. Government agencies are
            funnelling substantial resources into the procurement of
            sophisticated surveillance and crime analytics systems, including
            social media and internet communications surveillance systems, as
            well as video surveillance and data analytics systems to be utilised
            in public spaces including railways and airports, as well as across
            public spaces in cities.
          </p>
          <p>
            ADMS is transforming the face of law enforcement and the criminal
            justice system. Historical police practices, encoded in the often
            archaic frameworks in policing regulation like the police manuals or
            the police acts &ndash; are being supplemented or supplanted by
            &lsquo;data-driven&rsquo; decisions through the use of algorithmic
            systems. These systems are being used to determine who gets policed
            &ndash; evidenced through so-called &lsquo;predictive
            policing&rsquo; systems like the CMAPS used by the Delhi Police to
            indicate &lsquo;criminal hotspots&rsquo;, or the &lsquo;sentiment
            analysis&rsquo; software used by Mumbai and Uttar Pradesh Police,
            which scans social media to &lsquo;alert&rsquo; police forces of
            potential areas of disturbance.
          </p>
          <p>
            ADMS is also being used to expand the reach of policing beyond the
            restrictions imposed by the beat of a constable or the traditional
            jurisdiction of a police station. ADMS is moving policing from
            targeted, suspicion-driven policing and surveillance, which is
            triggered by police procedure and legal rules, to programmatic and
            ubiquitous surveillance triggered by algorithmic thresholds and
            logics.<sup
              ><a href="#sdfootnote5sym" name="sdfootnote5anc"
                ><sup>5</sup></a
              ></sup
            >
          </p>
          <p>
            ADMS is transforming the role and function of policing institutions
            in India, and not always in a positive way. When automated systems
            make decisions about whom to surveil, police and investigate, it can
            embroil individuals within a web of surveillance and incarceration,
            and, in particular, can reinforce systematic failures within a
            policing system in dire need of reform &ndash; including systematic
            discrimination towards marginalised populations.
          </p>
          <p>
            There is very little empirical evidence of how ADMS is impacting law
            enforcement in India.<sup
              ><a href="#sdfootnote6sym" name="sdfootnote6anc"
                ><sup>6</sup></a
              ></sup
            >
            While private companies and bureaucrats tout the effectiveness and
            accuracy of these systems, the automated turn in policing has not
            been scrutinised for its reliability, nor has there been any
            systematic effort at understanding ADMS use in policing and its
            impact on civil liberties or community harms. There has also been no
            systematic attempt at revising police practice or procedure &ndash;
            from policing manuals to forensic practice &ndash; to contend with
            or govern the use of ADMS.
          </p>
          <p>
            How can we ensure that ADMS in policing and criminal justice
            institutions is not used for unjust surveillance and punishment?
          </p>
          <blockquote cite="http://">
            How can we ensure that ADMS in policing and criminal justice
            institutions is not used for unjust surveillance and punishment?
          </blockquote>
        </div>
      </b-modal>
    </div>

    <div class="modal-button-container">
      <b-button class="modal-button" v-b-modal="'case-study-10'"
        >[Case Study: ADMS in Smart Cities]</b-button
      >
      <b-modal id="case-study-10" size="xl" hide-footer>
        <div></div>
        <div class="d-block text-left">
          <h3>Case Study: ADMS in Smart Cities</h3>
          <p>
            In June, 2015, the Government of India launched the Smart Cities
            Mission, a project which envisages networked digital technologies at
            the heart of managing urban spaces and livelihoods. India&rsquo;s
            Smart City project aims to create massive, city-wide digital
            infrastructure which can solve mundane and persistent issues of
            urban governance &ndash; providing basic utilities, ensuring citizen
            safety, and making cities &lsquo;future proof&rsquo;. ADMS are now
            routinely embedded in public infrastructure, responsible for
            decisions about our lives and livelihoods &ndash; from safety and
            sanitation, to the supply of basic utilities like electricity and
            water.<sup
              ><a href="#sdfootnote7sym" name="sdfootnote7anc"
                ><sup>7</sup></a
              ></sup
            >
          </p>
          <p>
            Smart City projects are important institutional forces behind the
            proliferation of ADMS in India. The models of urban governance in
            the Smart City are quite explicit in their attempts at governance
            through surveillance and datafication, both of urban environments
            and residents.<sup
              ><a href="#sdfootnote8sym" name="sdfootnote8anc"
                ><sup>8</sup></a
              ></sup
            >
            Integrated Command and Control Centres, connected by city-wide
            Closed Circuit TV&rsquo;s, use &lsquo;intelligent&rsquo; algorithmic
            machine vision tools to identify and alert officials of
            &lsquo;loitering&rsquo; citizens, or allow city police to predict
            possible violent crimes.<sup
              ><a href="#sdfootnote9sym" name="sdfootnote9anc"
                ><sup>9</sup></a
              ></sup
            >
            In the &lsquo;smart cities&rsquo; of Chandigarh, Nagpur and Indore,
            workers who maintain urban infrastructure are fitted with
            &lsquo;Human Efficiency Trackers&rsquo; which automatically deduct
            pay if they depart from the work schedules or routes determined by
            algorithmic systems, not only normalising invasive surveillance of
            individuals, but also undermining worker agency and channels of
            negotiation and grievance redress.
          </p>
          <p>
            ADMS in Smart Cities are also used to make decisions about the
            design of urban infrastructures, which are based on digital inputs
            gathered, for example, from sensored utility networks, or road
            transportation systems. In Bengaluru, IBM&rsquo;s &lsquo;smart
            water&rsquo; solutions have attempted to use Big Data analytics to
            make decisions about water supply infrastructure.<sup
              ><a href="#sdfootnote10sym" name="sdfootnote10anc"
                ><sup>10</sup></a
              ></sup
            >
            Intelligent Traffic Management Systems are used in conjunction with
            cameras and environmental sensors to determine traffic in cities
            like Chennai, Bengaluru and New Delhi, and to assist in planning for
            transport and mobility infrastructure.
          </p>
          <p>
            Smart Cities in India are being enabled through the privatisation of
            urban infrastructure and a departure from democratic participation
            and modes of governance. &lsquo;Public Private Partnerships&rsquo;
            abound, and the city governance is corporatised as a &lsquo;Special
            Purpose Vehicle&rsquo; &ndash; not quite state, neither entirely
            corporate &ndash; ostensibly to remove messy obstacles towards urban
            development, but in the process privatising essential utilities and
            shielding actors and institutions from accountability for digital
            infrastructure.
          </p>
          <p>
            The institution of the Smart City may be leading us towards
            privatised, opaque and exclusionary digital infrastructures, and
            routine surveillance of urban residents. How do citizens participate
            in and demand accountability for automated decision-making in our
            &lsquo;Smart Cities&rsquo;?
          </p>
          <blockquote cite="http://">
            <p>
              How do citizens participate in and demand accountability for
              automated decision-making in our &lsquo;Smart Cities&rsquo;?
            </p>
          </blockquote>
        </div>
      </b-modal>
    </div>

    <div class="modal-button-container">
      <b-button class="modal-button" v-b-modal="'case-study-11'"
        >[Case Study: ADMS in Welfare Administration]</b-button
      >
      <b-modal id="case-study-11" size="xl" hide-footer>
        <div class="d-block text-left">
          <h3>Case Study: ADMS in Welfare Administration</h3>
          <p>
            In 2018, the Supreme Court of India upheld the constitutionality of
            the Government of India&rsquo;s Unique Identification Project, or
            <em>Aadhaar.</em
            ><sup
              ><a href="#sdfootnote11sym" name="sdfootnote11anc"
                ><sup>11</sup></a
              ></sup
            >In responding to the argument that the biometric technologies used
            to authenticate individual claims to welfare entitlements were based
            on probabilistic techniques, and were inherently exclusionary, the
            Court held that a technology which afforded access to social welfare
            could not be invalidated on the grounds of &lsquo;exclusion of a
            few&rsquo;.
          </p>
          <p>
            <em>Aadhaar </em>laid the foundation for a proliferation of ADMS and
            algorithmic tools within government welfare schemes &ndash; from
            determining eligibility for housing, to identification for ration
            and utility subsidies, to determining welfare fraud in
            government-sponsored credit programmes. As noted by the UN Special
            Rapporteur on Extreme Poverty, these systems are leading us to a
            &lsquo;digital welfare dystopia&rsquo; - a rights-free zone with no
            protections or accountability to preserve institutions and ideals of
            social security.<sup
              ><a href="#sdfootnote12sym" name="sdfootnote12anc"
                ><sup>12</sup></a
              ></sup
            >
          </p>
          <p>
            The algorithmic turn towards the digital welfare state is apparent
            from programmes like the Government of Telangana&rsquo;s Samagra
            Vedika, which uses machine learning to make decisions about
            eligibility for housing and pension schemes, or the Government of
            Orissa&rsquo;s Kalia scheme, in which a private company provided
            &lsquo;big data analytics&rsquo; solutions to purge the
            Government&rsquo;s list of welfare beneficiaries, only to be faced
            with
            <a
              href="https://www.newindianexpress.com/states/odisha/2019/sep/19/number-of-ineligible-kalia-beneficiaries-is-only-32000-not-341-lakh-minister-2035722.html"
              >substantial backlash</a
            >
            from legitimate beneficiaries.
          </p>
          <p>
            ADMS systems offer the possibility of efficiency and neutrality in
            welfare administration, which is a major attraction for
            resource-starved bureaucracies tasked with a range of administrative
            functions. However, these systems are being deployed without any
            critical interrogation regarding their limitations and their
            consequences. Systems of &lsquo;fraud detection&rsquo; and
            beneficiary eligibility are utilising obscure and uncertain metrics
            under the guise of &lsquo;AI&rsquo; and Big Data to make judgements
            about individual identities and claims, and ultimately, these
            technologies may become a barrier to entitlements, instead of a
            means to access welfare.
          </p>
          <blockquote cite="http://">
            How do we challenge ADMS that are used to dispossess people of their
            rights and entitlements?
          </blockquote>
        </div>
      </b-modal>
    </div>

    <div>
      <b-img
        center
        style="width: 100%"
        src="../../public/pimg2.png"
        fluid
        alt="till link do us apart"
      ></b-img>
    </div>
    <!-- second heading -->

    <h2>The Regulatory Landscape of ADMS in India</h2>
    <p>
      There is no statute or legislative framework which explicitly attempts to
      regulate ADMS, algorithms, or Artificial Intelligence in India across
      contexts. However, ADMS regulation can be examined from how the law
      interfaces with its different components &ndash; namely, data and
      databases, algorithms and computer programmes, and within its sectoral and
      context-specific applications.
    </p>
    <p><strong>Regulation of Data and Databases</strong></p>
    <p>
      One legal framework which is pertinent to ADMS is that around privacy and
      the protection of personal data &ndash; particularly since many
      consequential ADMS are reliant upon the algorithmic processing of personal
      information. In India,
      <a
        href="https://cis-india.org/internet-governance/blog/comments-on-the-it-reasonable-security-practices-and-procedures-and-sensitive-personal-data-or-information-rules-2011"
        >Section 43A</a
      >
      of the Information Technology Act, 2000, attempts to regulate the use of
      data by private entities, and the Sensitive Data and Personal Information
      Rules, 2011. However, this legal framework does not apply to public
      agencies and government establishments, and has significant limitations in
      terms of its scope, the agency it provides to individuals to control
      personal data, as well as the structural mechanisms it establishes for
      data protection. While a more comprehensive &lsquo;<a
        href="https://www.prsindia.org/billtrack/personal-data-protection-bill-2019"
        >Personal Data Protection Bill, 2019</a
      >&rsquo; has been deliberated by the Government of India, as at the time
      of writing, it has not been enacted.
    </p>
    <p>
      The Supreme Court of India has articulated a fundamental Right to Privacy
      under the Constitution of India, which explicitly includes the right to
      informational privacy, self-determination over personal data, as well as
      agency over intimate decisions.<sup
        ><a href="#sdfootnote13sym" name="sdfootnote13anc"><sup>13</sup></a></sup
      >
      While there has been no explicit application of the Right to Privacy to
      automated data processing within ADMS or AI, it is a touchstone to assess
      and challenge harmful systems.
    </p>
    <p><strong>Regulation of Algorithms and Data Processing</strong></p>
    <p>
      ADMS deployed within specific projects or systems are occasionally the
      subject of specific regulations. For example, the
      <a
        href="http://legislative.gov.in/actsofparliamentfromtheyear/aadhaar-targeted-delivery-financial-and-other-subsidies-benefits-and"
        >Aadhaar Act, 2016</a
      ><em
        ><a
          href="http://legislative.gov.in/actsofparliamentfromtheyear/aadhaar-targeted-delivery-financial-and-other-subsidies-benefits-and"
          >,</a
        ></em
      >attempts to regulate the functioning of the Government of India&rsquo;s
      Unique Identification project by specifying the standards of softwares and
      other technologies to be used within the ADMS systems deployed by Aadhaar,
      such as biometric authentication systems. Similarly, the Security and
      Exchange Board of India (SEBI) has
      <a
        href="https://www.sebi.gov.in/legal/circulars/may-2019/reporting-for-artificial-intelligence-ai-and-machine-learning-ml-applications-and-systems-offered-and-used-by-mutual-funds_42932.html"
        >auditing</a
      ><a
        href="https://www.sebi.gov.in/legal/circulars/may-2019/reporting-for-artificial-intelligence-ai-and-machine-learning-ml-applications-and-systems-offered-and-used-by-mutual-funds_42932.html"
        >requirements</a
      >
      for financial actors utilising AI or ML systems.
    </p>
    <p>
      However, there are no regulations specific to algorithmic systems within
      government systems or other consequential decision-making systems, which
      specify standards or structures for ensuring transparency and
      accountability for certain broad classes of algorithmic systems (as, for
      example, under the
      <a href="https://www.republique-numerique.fr/pages/in-english"
        >French Digital Republic Act</a
      >). Similarly, there are no norms around how to audit or investigate
      algorithmic systems used within public or private agencies, which is a
      necessary starting point for determining whether a system is functioning
      as it should, and what kinds of assumptions or biases an algorithmic
      system may embody.
    </p>
    <p>
      Legal systems around the world are increasingly recognising algorithmic
      systems as sites of regulation, to ensure that they abide by important
      rights and values within those jurisdictions. For example, the General
      Data Protection Regulation (GDPR) in the European Union recognises the
      need to
      <a
        href="https://ec.europa.eu/newsroom/article29/item-detail.cfm?item_id=612053"
        >provide protections against decisions made by automated systems</a
      >
      which have legal consequences, including the right to have human
      involvement in such decisions, as well as to demand explanations for such
      decisions. Similarly, governments are mooting approaches towards
      structural regulation of consequential algorithmic systems.
      <a
        href="https://www.congress.gov/bill/116th-congress/house-bill/2231/all-info"
        >The Algorithmic Accountability Act</a
      >
      introduced in the USA, for example, attempts to regulate the use of
      certain algorithmic systems through mandatory reporting, audits and impact
      assessments.
    </p>
    <p>
      <strong>Context-Specific </strong
      ><strong>Regulations on Use of ADMS</strong>
    </p>
    <p>
      In many implementations of ADMS, its regulation will depend on the
      specific legal and institutional context within which it is deployed. For
      example, elements of the Code of Criminal Procedure, State Police Manuals
      and laws which regulate police action in general, will determine how ADMS
      is used or regulated in police forces; similarly, principles guiding the
      conduct of elections, located within laws like the Representation of
      People&rsquo;s Act, will regulate the use of ADMS within those contexts.
      However, even within these specific contexts where ADMS is widely
      deployed, there is no translation of broad legal principles into
      regulatory practice, for example, through rules or regulations around the
      use or deployments of ADMS. It will be necessary to build on
      sector-specific and context-specific regulatory frameworks to incorporate
      necessary protections against ADMS.
    </p>
    <p>
      There is no single regulatory solution for harmful uses of ADMS in India.
      However, one important starting point should be to advocate for a strong
      data protection and private legislation which can incorporate procedural
      protections against ADMS. India&rsquo;s long-awaited privacy legislation
      &ndash; the
      <a
        href="http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf"
        ><u>Personal Data Protection Bill, 2019</u></a
      >
      &ndash; is currently being deliberated by members of a Joint Committee of
      the Houses of Parliament. The Committee has its work cut out for it
      &ndash; the PDP Bill, while progressive on many fronts, suffers from
      several lacunae and needs to be future-proofed. One aspect that the PDP
      Bill must account for is whether it is sufficient for an era of
      &lsquo;Artificial Intelligence&rsquo; and &lsquo;Big Data&rsquo;, where
      personal data is used to predict and control the behavior of individuals.
    </p>
    <div>
      <b-button class="modal-button" v-b-modal="'case-study-12'"
        >[Case Study: India’s privacy law needs to incorporate rights against
        the machine]</b-button
      >
      <b-modal id="case-study-12" size="xl" hide-footer>
        <div></div>
        <div class="d-block text-left">
          <h3>
            Case Study: India’s privacy law needs to incorporate rights against
            the machine
            <sup
              ><a href="#sdfootnote14sym" name="sdfootnote14anc"
                ><sup>14</sup></a
              ></sup
            >
          </h3>
          <p>
            India&rsquo;s long-awaited privacy legislation &ndash; the<a
              href="http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf"
              ><u>Personal Data Protection Bill, 2019</u></a
            >
            &ndash; is currently being deliberated by members of a Joint
            Committee of the Houses of Parliament. The Committee has its work
            cut out for it &ndash; the PDP Bill, while progressive on many
            fronts, suffers from several lacunae and needs to be future-proofed.
            One aspect that the PDP Bill must account for is whether it is
            sufficient for an era of &lsquo;Artificial Intelligence&rsquo; and
            &lsquo;Big Data&rsquo;, where personal data is used to predict and
            control the behavior of individuals.
          </p>
          <p>
            Will the PDP Bill curtail the tyranny of the machine? The Bill does,
            to a large extent, limit the effects of automated decisions,
            particularly by allowing individuals to control their personal data
            and its use, as well as structural changes aimed at entities using
            personal data. In particular, the Bill provides individuals with a
            (limited) right to access, rectify and erase personal data, which
            includes inferences for the purpose of profiling. Profiling, in
            turn, is defined as &ldquo;any form of processing of personal data
            that analyses or predicts aspects concerning the behaviour,
            attributes or interests of a data principal.&rdquo; Therefore, the
            Bill takes express cognizance of profiling of individuals by
            automated processing and to some degree allows individuals to
            control such profiling. However, despite such recognition, it
            provides few protections against the specific harms from automated
            profiling and decision-making, leaving the Data Protection Authority
            to specify certain &lsquo;additional safeguards&rsquo; against
            profiling for only a subset of personal data deemed to be
            &lsquo;sensitive&rsquo;.
          </p>
          <p>
            In order to be a robust legislation for our &lsquo;AI&rsquo; era, we
            need to implement expanded protections against automated decisions.
            One way of extending such protection would be to draw from the legal
            tradition of &lsquo;<a
              href="https://openscholarship.wustl.edu/cgi/viewcontent.cgi?article=1166&amp;context=law_lawreview"
              ><u>due process&rsquo;</u></a
            >, which ensures that decisions affecting individuals incorporate
            certain procedural guarantees which are essential to ensuring that
            they are fair and non-arbitrary. These guarantees include the right
            to obtain a justification or explanation of decisions, the right to
            obtain information which was used to make the decision, the right to
            be heard and have one&rsquo;s views incorporated in the decision, as
            well as the right to contest or appeal a decision. In the absence of
            such protections, legal mechanisms should exist which ensure that
            individuals have the right to object to automated decisions and to
            have such decisions be subject to meaningful human oversight.
          </p>
          <p>
            However, placing the burden of contesting decisions on affected
            individuals will not be sufficient. To overcome this burden, data
            protection law like the PDP Bill could incorporate structural
            protections to ensure that automated profiling is fair and
            transparent. These protections may include, for example, regular
            audits on the data and techniques used in profiling, to ensure its
            robustness and safeguard against systematic discrimination. Further,
            the logic or rules of automated processing of data for purposes of
            proofing must be made transparent by default. Different levels of
            protection may be offered in different circumstances, according to
            the potential harm which may be caused to the subject of the
            decision.
          </p>
          <p>
            Opaque and unaccountable AI systems are antithetical to our
            constitutional ideals of privacy. The Supreme Court of India has<a
              href="https://indiankanoon.org/doc/91938676/"
              ><u>noted</u></a
            >
            that decisional autonomy &ndash; the freedom to make informed
            choices for oneself &ndash; is a core component of the fundamental
            right to privacy under the constitution. However, AI systems limit
            our ability to make such informed decisions by classifying and
            typecasting us according to their own secret rules. As we hurl
            headfirst into the age of &lsquo;AI&rsquo;, our legal systems must
            stand up to the task of protecting our privacy and decisional
            autonomy.
          </p>

          <blockquote cite="http://">
            However, AI systems limit our ability to make such informed
            decisions by classifying and typecasting us according to their own
            secret rules. As we hurl headfirst into the age of &lsquo;AI&rsquo;,
            our legal systems must stand up to the task of protecting our
            privacy and decisional autonomy.
          </blockquote>
        </div>
      </b-modal>
    </div>
    <div class="footnotes">
      <div>
        <p>
          <a href="#sdfootnote1anc" name="sdfootnote1sym">1</a> Chandrasekhara
          MK, Shanthi B and Mahabala HN, &lsquo;Can Community Health Workers
          Screen under 5yr Children with Computer Program&rsquo; (1994) 61 The
          Indian Journal of Pediatrics 567
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote2anc" name="sdfootnote2sym">2</a> Bajaj KK, Dubash
          RK and Kowalski R, &lsquo;Central Government Pension Rules as a Logic
          Program&rsquo; in S Ramani, R Chandrasekar and KSR Anjaneyulu (eds),
          <em>Knowledge Based Computer Systems</em>, vol 444 (Springer-Verlag
          1990) &lt;<a href="http://link.springer.com/10.1007/BFb0018365"
            ><u>http://link.springer.com/10.1007/BFb0018365</u></a
          >&gt;
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote3anc" name="sdfootnote3sym">3</a
          ><em>See, for example, &lsquo;</em>Working Document: Enforcement
          Mechanisms for Responsible #AIforAll&rsquo;, NITI Ayog, (2020)
          &lt;https://niti.gov.in/sites/default/files/2020-11/Towards-Responsible-AI-Enforcement-of-Principles.pdf&gt;
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote4anc" name="sdfootnote4sym">4</a> Basu, A.,
          Hickok, E., &lsquo;Artificial Intelligence in the Governance Sector in
          India&rsquo;, The Centre for Internet and Society, India,
          &lt;https://cis-india.org/internet-governance/ai-and-governance-case-study-pdf&gt;
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote5anc" name="sdfootnote5sym">5</a> Brayne S,
          &lsquo;Big Data Surveillance: The Case of Policing&rsquo; (2017) 82
          American Sociological Review 977
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote6anc" name="sdfootnote6sym">6</a> There are
          progressive efforts to study the use of ADMS in policing, see, for
          example, Narayan, S, and Marda, V, &lsquo;Data in New Delhi&rsquo;s
          Predictive Policing System, Proceedings of the 2020 Conference on
          Fairness, Accountability, and Transparency, &lt;<a
            href="https://dl.acm.org/doi/abs/10.1145/3351095.3372865"
            ><u>https://dl.acm.org/doi/abs/10.1145/3351095.3372865</u></a
          >&gt;, &lsquo;Project Panoptic&rsquo;, Internet Freedom Foundation,
          &lt;<a href="https://internetfreedom.in/tag/project-panoptic"
            ><u>https://internetfreedom.in/tag/project-panoptic</u></a
          >&gt;; Mathews H V, Sinha A., &lsquo;Use of Algorithmic Techniques for
          Law Enforcement&rsquo;, 55(23) Economic and Political Weekly (2020).
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote7anc" name="sdfootnote7sym">7</a> A snapshot of
          projects relevant to ADMS in Smart Cities can be seen here -
          <a
            href="http://smartcities.gov.in/content/innerpage/smart-solutions.php"
            ><u
              >http://smartcities.gov.in/content/innerpage/smart-solutions.php</u
            ></a
          >.
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote8anc" name="sdfootnote8sym">8</a> Kitchin R,
          &lsquo;The Ethics of Smart Cities and Urban Science&rsquo; (2016) 374
          Philosophical Transactions of the Royal Society A: Mathematical,
          Physical and Engineering Sciences 20160115
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote9anc" name="sdfootnote9sym">9</a> See, for
          example, the &lsquo;Model RFP For Implementation of Smart City
          Solutions&rsquo;,
          https://smartnet.niua.org/sites/default/files/resources/vol_2_first_draft_rfp_for_system_integrator_scope_of_work_0.pdf
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote10anc" name="sdfootnote10sym">10</a> Taylor L and
          Richter C, &lsquo;The Power of Smart Solutions: Knowledge,
          Citizenship, and the Datafication of Bangalore&rsquo;s Water
          Supply&rsquo; (2017) 18 Television &amp; New Media 721
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote11anc" name="sdfootnote11sym">11</a
          ><em>Justice K.S. Puttaswamy v Union of India</em> (2019) 1 SCC 1
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote12anc" name="sdfootnote12sym">12</a> UNGA,
          &lsquo;Report Of The Special Rapporteur On Extreme Poverty And Human
          Rights&rsquo;, A/74/493, (October 11 2019).
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote13anc" name="sdfootnote13sym">13</a>Justice K.S.
          Puttaswamy v. Union of India (2017) 10 SCC 1.
        </p>
      </div>
      <div>
        <p>
          <a href="#sdfootnote14anc" name="sdfootnote14sym">14</a> Excerpt from
          an article originally published in Medianama<em>, available at </em
          >https://www.medianama.com/2020/05/223-indias-privacy-law-needs-to-incorporate-rights-against-the-machine/
        </p>
      </div>
    </div>
  </b-tab>
</template>

<script></script>

<style lang="scss" scoped></style>
