<template>
  <b-tab title="Laws, Policies, Actors and Institutions" active>
    <p>
      To understand the consequences of the use of ADMS and AI, it is imperative
      to explore the political, legal and institutional context within which its
      development and deployment is taking place. This section marks out the
      legal and institutional frameworks within which AI and ADMS are being
      adopted in India, and the policies and actors which are shaping the manner
      in which it is developed and deployed.&nbsp;
    </p>
    <p><strong>The Politics of AI Policy in India</strong></p>
    <p>
      The use of &lsquo;AI&rsquo;-based computer systems in supporting
      government administration and decision-making in India can be traced back
      to at-least the 1980&rsquo;s, with the establishment of research centres
      for AI, like the Centre for the Development of Advanced Computing, or
      &lsquo;nodal centres&rsquo; within the Department of Electronics which
      developing AI systems for government administration, supported by
      international development organisations like the UNDP.
    </p>
    <p>
      Early examples of ADMS in India include systems like Eklavya, a software
      system which aided frontline child health workers with making decisions
      about diagnosis, health risk and future action for healthcare. Similarly,
      there is documented use of &lsquo;Automated Legal Reasoning Systems&rsquo;
      under the Knowledge Based Computer Systems programme of the Government of
      India. These systems implemented rule-based and logic-based programmes for
      decision-making, which were piloted in the fields of income tax, pension
      and customs. These systems attempted to encode the logic of statutory
      rules in these fields into programmatic computer languages in order to aid
      bureaucrats in complex legal and administrative problems. These early
      examples are indicative of the Government of India&rsquo;s desire to embed
      ADMS within government administration to ensure consistency in
      decision-making, and to assist administrative agencies in navigating and
      administering complex rule-based systems.&nbsp;
    </p>
    <p>
      The contemporary use of ADMS in India is also justified based on their
      efficiency in solving complex problems in government administration.
      However, today, ADMS adoption is occurring in a very different
      technological and political context, and this transformation is critical
      in understanding the role that ADMS plays in public agencies in India
      today.
    </p>
    <p>
      Developing &lsquo;AI&rsquo; and promoting computational data analytics
      within the government and the private sector alike has recently become a
      policy priority for the Government of India, as well as various state
      governments, over the last few years. Various &lsquo;AI&rsquo; policies
      have been released by the Government of India &ndash; from the government
      policy agency NITI Aayog&rsquo;s National Strategy for AI, to reports of
      expert committees constituted by the Ministry of Electronics and IT
      &ndash; which see AI as a transformational technology, and as a crucial
      &lsquo;factor of production&rsquo; for obtaining higher economic growth in
      the information economy. These policy documents have called for greater
      development and adoption of &lsquo;AI&rsquo; across the private and public
      sectors, ranging from healthcare to agriculture. According to some policy
      documents, &lsquo;AI&rsquo; is expected to operate as the infrastructure
      through which a number of applications and information-based tools can be
      built and used. For example, the Department of Telecommunications has
      articulated a vision for an &lsquo;AI Stack&rsquo; &ndash; a technological
      architecture for AI as infrastructure to be developed and used across a
      number of applications and domains.
    </p>
    <p>
      <br />AI development has also been a policy agenda for state and local
      governments. Telangana, for example, has reflected its proposals to
      promote and utilise ADMS and AI systems across different industries and
      uses, in the &lsquo;2020 Year of AI Vision&rsquo;. Other documents like
      &lsquo;Tamil Nadu Safe and Ethical AI Policy&rsquo; also indicate a
      growing recognition of the need to contend with emerging ethical issues
      arising from the use of AI, including fairness, transparency and
      accountability.
    </p>

    <p>
      The vision of &lsquo;AI&rsquo; articulated in these documents is one of a
      &lsquo;public good&rsquo;, championed by private firms and companies
      developing these technologies, and incentivised and legitimised through
      government policy, investment,and &lsquo;public-private
      partnerships&rsquo;. This vision of AI has also influenced key regulatory
      and policy developments in India, particularly regarding the governance of
      digital data. Government policy documents, such as Economic Survey of
      India of 2018-2019, the Draft E-Commerce Policy and the Report of the
      Committee of Experts on Non-Personal Data, have attempted to reclassify
      &lsquo;data&rsquo; within digital environments as an economic asset, whose
      value can be &lsquo;unlocked&rsquo; or exploited through appropriately
      channeling them within AI or data analytics systems.
    </p>

    <blockquote cite="http://">
      The vision of &lsquo;AI&rsquo; articulated in these documents is one of a
      &lsquo;public good&rsquo;, championed by private firms and companies
      developing these technologies, and incentivised and legitimised through
      government policy, investment,and &lsquo;public-private
      partnerships&rsquo;.
    </blockquote>

    <p>
      The policy focus on spurring innovation through the deployment of
      government regulation has had a direct influence on legislative policy as
      well. The Personal Data Protection Bill, in 2019, had carved out specific
      exemptions for activities like Credit Scoring and Fraud Detection, which
      are common use cases for ADMS. Similarly, the PDP Bill also allowed for
      the acquisition of any &lsquo;non-personal&rsquo; data by the Government,
      for &lsquo;better targeting&rsquo; of services or for the formulation of
      &lsquo;evidence-based policy&rsquo; &ndash; once again evidencing attempts
      to use &lsquo;big data analytics&rsquo; within ADMS to make consequential
      policy and administrative decisions.
    </p>
    <p>
      While there has been an increasing recognition of the risks posed by
      delegating decision-making to automated systems and &lsquo;AI&rsquo;,
      particularly on risks to data protection and privacy, policy documents
      have understood these are primarily risks caused by technological failure,
      which can be allayed by appropriate technical standards (such as
      anonymisation of data, or through &lsquo;consent management
      systems&rsquo;).&nbsp;
    </p>
    <p>
      However, even as &lsquo;AI&rsquo; policy which emerges from India
      recognises some risks and harms in the development and deployment of AI,
      there is a disturbing lack of recognition or regulation around the systems
      currently in use and being deployed. As documented in this toolkit, many
      decisions consequential to individuals and communities are being delegated
      to algorithmic systems, varying in sophistication, but posing concerns
      &ndash; of democratic control, justice and self-determination &ndash;
      which are not reflected within policies which encourage the development
      and deployment of &lsquo;AI&rsquo; systems. In fact, even the documented
      deployment of current AI and Machine Learning systems does not reflect the
      concerns of data protection or &lsquo;ethical design&rsquo; which are
      envisaged in policy documents at the ministerial level, pointing to the
      complete absence of a structural framework to ensure accountability of
      ADMS on the ground, even as their harms are being recognised in policy.
      Instead, the development of these systems is taking place in a regulatory
      vacuum, resulting in a situation where important considerations of
      transparency, accountability and democratic control are not given their
      due regard.
    </p>
    <p>
      Taking the gaze away from high-level policy documents on AI released by
      government agencies, the development of ADMS in India is being shaped, in
      fact, by a network of public and private actors, norms and institutions,
      seemingly unguided by the visions of &lsquo;ethics&rsquo; or &lsquo;social
      good&rsquo; articulated in policy documents. The case studies below shine
      a light on actors and institutions responsible for developing and
      deploying ADMS in India.
    </p>

    <div>
      <b-button class="modal-button" v-b-modal="'case-study-9'"
        >[Case Study: ADMS in Policing]</b-button
      >
      <b-modal id="case-study-9" size="xl" hide-footer>
        <div></div>
        <div class="d-block text-left">
          <h3>Case Study: ADMS in Policing</h3>
          <p>
            Since 2016, the Federation of the Indian Chambers of Commerce and
            Industry (FICCI), a major industry association in India, has been
            instituting the &lsquo;Smart Policing Awards&rsquo;, ostensibly with
            the intention of promoting practices for the safety and security of
            Indians. The awardees over the last four years have included
            Automated Decision Making Systems like the Punjab Artificial
            Intelligence System (PAIS), Trinetra in Uttar Pradesh, and Automated
            Facial Recognition and Number-Plate Recognition Systems in Madhya
            Pradesh, among others.&nbsp;
          </p>
          <p>
            Looking over the awardees of &lsquo;Smart Policing&rsquo; gives a
            good indication of the directions in which technology use in
            policing is heading, and the actors driving this change. Since the
            Crime and Criminal Tracking Network System (CCTNS) was first
            projected as the digital infrastructure to enable
            &lsquo;smarter&rsquo; policing in India, there has been a
            proliferation of data-driven and digital surveillance-based
            technologies among policing agencies. Government agencies are
            funnelling substantial resources into the procurement of
            sophisticated surveillance and crime analytics systems, including
            social media and internet communications surveillance systems, as
            well as video surveillance and data analytics systems to be utilised
            in public spaces including railways and airports, as well as across
            public spaces in cities.
          </p>
          <p>
            ADMS is transforming the face of law enforcement and the criminal
            justice system. Historical police practices, encoded in the often
            archaic frameworks in policing regulation like the police manuals or
            the police acts &ndash; are being supplemented or supplanted by
            &lsquo;data-driven&rsquo; decisions through the use of algorithmic
            systems. These systems are being used to determine who gets policed
            &ndash; evidenced through so-called &lsquo;predictive
            policing&rsquo; systems like the CMAPS used by the Delhi Police to
            indicate &lsquo;criminal hotspots&rsquo;, or the &lsquo;sentiment
            analysis&rsquo; software used by Mumbai and Uttar Pradesh Police,
            which scans social media to &lsquo;alert&rsquo; police forces of
            potential areas of disturbance.
          </p>
          <p>
            ADMS is also being used to expand the reach of policing beyond the
            restrictions imposed by the beat of a constable or the traditional
            jurisdiction of a police station. ADMS is moving policing from
            targeted, suspicion-driven policing and surveillance, which is
            triggered by police procedure and legal rules, to programmatic and
            ubiquitous surveillance triggered by algorithmic thresholds and
            logics.
          </p>
          <p>
            ADMS is transforming the role and function of policing institutions
            in India, and not always in a positive way. When automated systems
            make decisions about whom to surveil, police and investigate, it can
            embroil individuals within a web of surveillance and incarceration,
            and, in particular, can reinforce systematic failures within a
            policing system in dire need of reform &ndash; including systematic
            discrimination towards marginalised populations.
          </p>
          <p>
            <br />There is very little empirical evidence of how ADMS is
            impacting law enforcement in India. While private companies and
            bureaucrats tout the effectiveness and accuracy of these systems,
            the automated turn in policing has not been scrutinised for its
            reliability, nor has there been any systematic effort at
            understanding ADMS use in policing and its impact on civil liberties
            or community harms. There has also been no systematic attempt at
            revising police practice or procedure &ndash; from policing manuals
            to forensic practice &ndash; to contend with or govern the use of
            ADMS.
          </p>
          <p>
            How can we ensure that ADMS in policing and criminal justice
            institutions is not used for unjust surveillance and punishment?
          </p>
          <blockquote cite="http://">
            How can we ensure that ADMS in policing and criminal justice
            institutions is not used for unjust surveillance and punishment?
          </blockquote>
        </div>
      </b-modal>
    </div>

    <div>
      <b-button class="modal-button" v-b-modal="'case-study-10'"
        >[Case Study: ADMS in Smart Cities]</b-button
      >
      <b-modal id="case-study-10" size="xl" hide-footer>
        <div></div>
        <div class="d-block text-left">
          <h3>Case Study: ADMS in Smart Cities</h3>
          <p>
            In June, 2015, the Government of India launched the Smart Cities
            Mission, a project which envisages networked digital technologies at
            the heart of managing urban spaces and livelihoods. India&rsquo;s
            Smart City project aims to create massive, city-wide digital
            infrastructure which can solve mundane and persistent issues of
            urban governance &ndash; providing basic utilities, ensuring citizen
            safety, and making cities &lsquo;future proof&rsquo;. ADMS are now
            routinely embedded in public infrastructure, responsible for
            decisions about our lives and livelihoods &ndash; from safety and
            sanitation, to the supply of basic utilities like electricity and
            water.
          </p>
          <p>
            Smart City projects are important institutional forces behind the
            proliferation of ADMS in India. The models of urban governance in
            the Smart City are quite explicit in their attempts at governance
            through surveillance and datafication, both of urban environments
            and residents. Integrated Command and Control Centres, connected by
            city-wide Closed Circuit TV&rsquo;s, use &lsquo;intelligent&rsquo;
            algorithmic machine vision tools to identify and alert officials of
            &lsquo;loitering&rsquo; citizens, or allow city police to predict
            possible violent crimes. In the &lsquo;smart cities&rsquo; of
            Chandigarh, Nagpur and Indore, workers who maintain urban
            infrastructure are fitted with &lsquo;Human Efficiency
            Trackers&rsquo; which automatically deduct pay if they depart from
            the work schedules or routes determined by algorithmic systems, not
            only normalising invasive surveillance of individuals, but also
            undermining worker agency and channels of negotiation and grievance
            redress.
          </p>
          <p>
            ADMS in Smart Cities are also used to make decisions about the
            design of urban infrastructures, which are based on digital inputs
            gathered, for example, from sensored utility networks, or road
            transportation systems. In Bengaluru, IBM&rsquo;s &lsquo;smart
            water&rsquo; solutions have attempted to use Big Data analytics to
            make decisions about water supply infrastructure. Intelligent
            Traffic Management Systems are used in conjunction with cameras and
            environmental sensors to determine traffic in cities like Chennai,
            Bengaluru and New Delhi, and to assist in planning for transport and
            mobility infrastructure.&nbsp;
          </p>
          <p>
            Smart Cities in India are being enabled through the privatisation of
            urban infrastructure and a departure from democratic participation
            and modes of governance. &lsquo;Public Private Partnerships&rsquo;
            abound, and the city governance is corporatised as a &lsquo;Special
            Purpose Vehicle&rsquo; &ndash; not quite state, neither entirely
            corporate &ndash; ostensibly to remove messy obstacles towards urban
            development, but in the process privatising essential utilities and
            shielding actors and institutions from accountability for digital
            infrastructure.
          </p>
          <p>
            The institution of the Smart City may be leading us towards
            privatised, opaque and exclusionary digital infrastructures, and
            routine surveillance of urban residents. How do citizens participate
            in and demand accountability for automated decision-making in our
            &lsquo;Smart Cities&rsquo;?
          </p>
          <p>
            How do citizens participate in and demand accountability for
            automated decision-making in our &lsquo;Smart Cities&rsquo;?
          </p>
          <blockquote cite="http://">
            <p>
              How do citizens participate in and demand accountability for
              automated decision-making in our &lsquo;Smart Cities&rsquo;?
            </p>
          </blockquote>
        </div>
      </b-modal>
    </div>

    <div>
      <b-button class="modal-button" v-b-modal="'case-study-11'"
        >[Case Study: ADMS in Welfare Administration]</b-button
      >
      <b-modal id="case-study-11" size="xl" hide-footer>
        <div class="d-block text-left">
          <h3>Case Study: ADMS in Welfare Administration</h3>
          <p>
            In 2018, the Supreme Court of India upheld the constitutionality of
            the Government of India&rsquo;s Unique Identification Project, or
            <em>Aadhaar.</em>In responding to the argument that the biometric
            technologies used to authenticate individual claims to welfare
            entitlements were based on probabilistic techniques, and were
            inherently exclusionary, the Court held that a technology which
            afforded access to social welfare could not be invalidated on the
            grounds of &lsquo;exclusion of a few&rsquo;.
          </p>
          <div>
            <b-img
              center
              style="width:100%"
              src="../../public/pimg2.png"
              fluid
              alt="till link do us apart"
            ></b-img>
          </div>
          <p>
            <em>Aadhaar </em>laid the foundation for a proliferation of ADMS and
            algorithmic tools within government welfare schemes &ndash; from
            determining eligibility for housing, to identification for ration
            and utility subsidies, to determining welfare fraud in
            government-sponsored credit programmes. As noted by the UN Special
            Rapporteur on Extreme Poverty, these systems are leading us to a
            &lsquo;digital welfare dystopia&rsquo; - a rights-free zone with no
            protections or accountability to preserve institutions and ideals of
            social security.
          </p>
          <p>
            The algorithmic turn towards the digital welfare state is apparent
            from programmes like the Government of Telangana&rsquo;s Samagra
            Vedika, which uses machine learning to make decisions about
            eligibility for housing and pension schemes, or the Government of
            Orissa&rsquo;s Kalia scheme, in which a private company provided
            &lsquo;big data analytics&rsquo; solutions to purge the
            Government&rsquo;s list of welfare beneficiaries, only to be faced
            with substantial backlash from legitimate beneficiaries.
          </p>
          <p>
            ADMS systems offer the possibility of efficiency and neutrality in
            welfare administration, which is a major attraction for
            resource-starved bureaucracies tasked with a range of administrative
            functions. However, these systems are being deployed without any
            critical interrogation regarding their limitations and their
            consequences. Systems of &lsquo;fraud detection&rsquo; and
            beneficiary eligibility are utilising obscure and uncertain metrics
            under the guise of &lsquo;AI&rsquo; and Big Data to make judgements
            about individual identities and claims, and ultimately, these
            technologies may become a barrier to entitlements, instead of a
            means to access welfare.
          </p>
          <blockquote cite="http://">
            How do we challenge ADMS that are used to dispossess people of their
            rights and entitlements?
          </blockquote>
        </div>
      </b-modal>
    </div>

    <!-- second heading -->

    <h2>The Regulatory Landscape of ADMS in India</h2>
    <p>
      There is no statute or legislative framework which explicitly attempts to
      regulate ADMS, algorithms, or Artificial Intelligence in India across
      contexts. However, ADMS regulation can be examined from how the law
      interfaces with its different components &ndash; namely, data and
      databases, algorithms and computer programmes, and within its sectoral and
      context-specific applications.
    </p>
    <p><strong>Regulation of Data and Databases</strong></p>
    <p>
      One legal framework which is pertinent to ADMS is that around privacy and
      the protection of personal data &ndash; particularly since many
      consequential ADMS are reliant upon the algorithmic processing of personal
      information. In India, Section 43A of the Information Technology Act,
      2000, attempts to regulate the use of data by private entities, and the
      Sensitive Data and Personal Information Rules, 2011. However, this legal
      framework does not apply to public agencies and government establishments,
      and has significant limitations in terms of its scope, the agency it
      provides to individuals to control personal data, as well as the
      structural mechanisms it establishes for data protection. While a more
      comprehensive &lsquo;Personal Data Protection Bill, 2019&rsquo; has been
      deliberated by the Government of India, as at the time of writing, it has
      not been enacted.&nbsp;
    </p>
    <p>
      The Supreme Court of India has articulated a fundamental Right to Privacy
      under the Constitution of India, which explicitly includes the right to
      informational privacy, self-determination over personal data, as well as
      agency over intimate decisions. While there has been no explicit
      application of the Right to Privacy to automated data processing within
      ADMS or AI, it is a touchstone to assess and challenge harmful systems.
    </p>
    <p><strong>Regulation of Algorithms and Data Processing</strong></p>
    <p>
      ADMS deployed within specific projects or systems are occasionally the
      subject of specific regulations. For example, the Aadhaar Act,
      2016<em>,</em>attempts to regulate the functioning of the Government of
      India&rsquo;s Unique Identification project by specifying the standards of
      softwares and other technologies to be used within the ADMS systems
      deployed by Aadhaar, such as biometric authentication systems. Similarly,
      the Security and Exchange Board of India (SEBI) has auditing requirements
      for financial actors utilising AI or ML systems.
    </p>
    <p>
      However, there are no regulations specific to algorithmic systems within
      government systems or other consequential decision-making systems, which
      specify standards or structures for ensuring transparency and
      accountability for certain broad classes of algorithmic systems (as, for
      example, under the French Digital Republic Act). Similarly, there are no
      norms around how to audit or investigate algorithmic systems used within
      public or private agencies, which is a necessary starting point for
      determining whether a system is functioning as it should, and what kinds
      of assumptions or biases an algorithmic system may embody.&nbsp;
    </p>
    <p>
      Legal systems around the world are increasingly recognising algorithmic
      systems as sites of regulation, to ensure that they abide by important
      rights and values within those jurisdictions. For example, the General
      Data Protection Regulation (GDPR) in the European Union recognises the
      need to provide protections against decisions made by automated systems
      which have legal consequences, including the right to have human
      involvement in such decisions, as well as to demand explanations for such
      decisions. Similarly, governments are mooting approaches towards
      structural regulation of consequential algorithmic systems. The
      Algorithmic Accountability Act introduced in the USA, for example,
      attempts to regulate the use of certain algorithmic systems through
      mandatory reporting, audits and impact assessments.
    </p>
    <p><strong>Context-Specific Regulations on Use of ADMS</strong></p>
    <p>
      In many implementations of ADMS, its regulation will depend on the
      specific legal and institutional context within which it is deployed. For
      example, elements of the Code of Criminal Procedure, State Police Manuals
      and laws which regulate police action in general, will determine how ADMS
      is used or regulated in police forces; similarly, principles guiding the
      conduct of elections, located within laws like the Representation of
      People&rsquo;s Act, will regulate the use of ADMS within those contexts.
      However, even within these specific contexts where ADMS is widely
      deployed, there is no translation of broad legal principles into
      regulatory practice, for example, through rules or regulations around the
      use or deployments of ADMS. It will be necessary to build on
      sector-specific and context-specific regulatory frameworks to incorporate
      necessary protections against ADMS.
    </p>
    <p>
      <br />There is no single regulatory solution for harmful uses of ADMS in
      India. However, one important starting point should be to advocate for a
      strong data protection and private legislation which can incorporate
      procedural protections against ADMS. India&rsquo;s long-awaited privacy
      legislation &ndash; the
      <a
        href="http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf"
        >Personal Data Protection Bill, 2019</a
      >
      &ndash; is currently being deliberated by members of a Joint Committee of
      the Houses of Parliament. The Committee has its work cut out for it
      &ndash; the PDP Bill, while progressive on many fronts, suffers from
      several lacunae and needs to be future-proofed. One aspect that the PDP
      Bill must account for is whether it is sufficient for an era of
      &lsquo;Artificial Intelligence&rsquo; and &lsquo;Big Data&rsquo;, where
      personal data is used to predict and control the behavior of individuals.
    </p>
    <div>
      <b-button class="modal-button" v-b-modal="'case-study-12'"
        >[Case Study: India’s privacy law needs to incorporate rights against the
        machine]</b-button
      >
      <b-modal id="case-study-12" size="xl" hide-footer>
        <div></div>
        <div class="d-block text-left">
          <h3>
            Case Study: India’s privacy law needs to incorporate rights against
            the machine
          </h3>
          <p>
            India&rsquo;s long-awaited privacy legislation &ndash; the<a
              href="http://164.100.47.4/BillsTexts/LSBillTexts/Asintroduced/373_2019_LS_Eng.pdf"
              >Personal Data Protection Bill, 2019</a
            >
            &ndash; is currently being deliberated by members of a Joint
            Committee of the Houses of Parliament. The Committee has its work
            cut out for it &ndash; the PDP Bill, while progressive on many
            fronts, suffers from several lacunae and needs to be future-proofed.
            One aspect that the PDP Bill must account for is whether it is
            sufficient for an era of &lsquo;Artificial Intelligence&rsquo; and
            &lsquo;Big Data&rsquo;, where personal data is used to predict and
            control the behavior of individuals.
          </p>
          <p>
            Will the PDP Bill curtail the tyranny of the machine? The Bill does,
            to a large extent, limit the effects of automated decisions,
            particularly by allowing individuals to control their personal data
            and its use, as well as structural changes aimed at entities using
            personal data. In particular, the Bill provides individuals with a
            (limited) right to access, rectify and erase personal data, which
            includes inferences for the purpose of profiling. Profiling, in
            turn, is defined as &ldquo;any form of processing of personal data
            that analyses or predicts aspects concerning the behaviour,
            attributes or interests of a data principal.&rdquo; Therefore, the
            Bill takes express cognizance of profiling of individuals by
            automated processing and to some degree allows individuals to
            control such profiling. However, despite such recognition, it
            provides few protections against the specific harms from automated
            profiling and decision-making, leaving the Data Protection Authority
            to specify certain &lsquo;additional safeguards&rsquo; against
            profiling for only a subset of personal data deemed to be
            &lsquo;sensitive&rsquo;.
          </p>
          <p>
            In order to be a robust legislation for our &lsquo;AI&rsquo; era, we
            need to implement expanded protections against automated decisions.
            One way of extending such protection would be to draw from the legal
            tradition of &lsquo;<a
              href="https://openscholarship.wustl.edu/cgi/viewcontent.cgi?article=1166&amp;context=law_lawreview"
              >due process&rsquo;</a
            >, which ensures that decisions affecting individuals incorporate
            certain procedural guarantees which are essential to ensuring that
            they are fair and non-arbitrary. These guarantees include the right
            to obtain a justification or explanation of decisions, the right to
            obtain information which was used to make the decision, the right to
            be heard and have one&rsquo;s views incorporated in the decision, as
            well as the right to contest or appeal a decision. In the absence of
            such protections, legal mechanisms should exist which ensure that
            individuals have the right to object to automated decisions and to
            have such decisions be subject to meaningful human oversight.
          </p>
          <p>
            However, placing the burden of contesting decisions on affected
            individuals will not be sufficient. To overcome this burden, data
            protection law like the PDP Bill could incorporate structural
            protections to ensure that automated profiling is fair and
            transparent. These protections may include, for example, regular
            audits on the data and techniques used in profiling, to ensure its
            robustness and safeguard against systematic discrimination. Further,
            the logic or rules of automated processing of data for purposes of
            proofing must be made transparent by default. Different levels of
            protection may be offered in different circumstances, according to
            the potential harm which may be caused to the subject of the
            decision.
          </p>
          <p>
            Opaque and unaccountable AI systems are antithetical to our
            constitutional ideals of privacy. The Supreme Court of India has<a
              href="https://indiankanoon.org/doc/91938676/"
              >noted</a
            >
            that decisional autonomy &ndash; the freedom to make informed
            choices for oneself &ndash; is a core component of the fundamental
            right to privacy under the constitution. However, AI systems limit
            our ability to make such informed decisions by classifying and
            typecasting us according to their own secret rules. As we hurl
            headfirst into the age of &lsquo;AI&rsquo;, our legal systems must
            stand up to the task of protecting our privacy and decisional
            autonomy.
          </p>
          <blockquote cite="http://">
            However, AI systems limit our ability to make such informed
            decisions by classifying and typecasting us according to their own
            secret rules. As we hurl headfirst into the age of &lsquo;AI&rsquo;,
            our legal systems must stand up to the task of protecting our
            privacy and decisional autonomy.
          </blockquote>
        </div>
      </b-modal>
    </div>
  </b-tab>
</template>

<script></script>

<style lang="scss" scoped></style>
